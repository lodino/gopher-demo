{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83ab276",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb814f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.652422Z",
     "start_time": "2021-10-24T03:35:54.539462Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90528c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.656200Z",
     "start_time": "2021-10-24T03:35:54.654089Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d4f9b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.788933Z",
     "start_time": "2021-10-24T03:35:54.657386Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/lodino/Desktop/CSE250A/hws/hw4/hw4_vocab.txt', 'r') as f:\n",
    "    vocabs = f.read().strip('\\n').split('\\n')\n",
    "    \n",
    "with open('/Users/lodino/Desktop/CSE250A/hws/hw4/hw4_unigram.txt', 'r') as f:\n",
    "    unigrams = f.read().strip('\\n').split('\\n')\n",
    "    unigram_arr = np.array([int(cnt) for cnt in unigrams])\n",
    "    \n",
    "with open('/Users/lodino/Desktop/CSE250A/hws/hw4/hw4_bigram.txt', 'r') as f:\n",
    "    bigrams = f.read().strip('\\n').split('\\n')\n",
    "    bigram_mat = np.zeros((len(vocabs), len(vocabs)))\n",
    "    for bigram in bigrams:\n",
    "        ls = bigram.split('\\t')\n",
    "        w1_idx = int(ls[0])-1\n",
    "        w2_idx = int(ls[1])-1\n",
    "        cnt = int(ls[2])\n",
    "        bigram_mat[w1_idx, w2_idx] = cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8f87d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75a16f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.794022Z",
     "start_time": "2021-10-24T03:35:54.789919Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAS: 0.004955\n",
      "WITH: 0.004555\n",
      "WILL: 0.002483\n",
      "WERE: 0.002295\n",
      "WHO: 0.002148\n",
      "WOULD: 0.001955\n",
      "WHICH: 0.001738\n",
      "WE: 0.001464\n",
      "WHEN: 0.001285\n",
      "WHAT: 0.000758\n",
      "WHILE: 0.000571\n",
      "WEEK: 0.000572\n",
      "WHERE: 0.000517\n",
      "WORLD: 0.000441\n",
      "WORK: 0.000442\n",
      "WAY: 0.00042\n",
      "WELL: 0.000413\n",
      "WAR: 0.000392\n",
      "WEDNESDAY: 0.000366\n",
      "WEST: 0.000363\n",
      "WHITE: 0.00032\n",
      "WANT: 0.000313\n",
      "WASHINGTON: 0.000312\n",
      "WITHOUT: 0.000299\n",
      "WHETHER: 0.000279\n",
      "WORKERS: 0.000264\n",
      "WOMEN: 0.000223\n",
      "WEEKS: 0.00021\n",
      "WE'RE: 0.000211\n"
     ]
    }
   ],
   "source": [
    "unigram_cpts = unigram_arr/unigram_arr.sum()\n",
    "for word_idx, word in enumerate(vocabs):\n",
    "    if word[0]=='W':\n",
    "        print(f'{word}: {round(unigram_cpts[word_idx], 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb8f2b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35832777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.798793Z",
     "start_time": "2021-10-24T03:35:54.796612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# linear search\n",
    "def find_word_idx(w):\n",
    "    for word_idx, word in enumerate(vocabs):\n",
    "        if w==word:\n",
    "            return word_idx\n",
    "    raise Exception(f'Word \"{w}\" not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5744d0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.802890Z",
     "start_time": "2021-10-24T03:35:54.799781Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bigram_cpts = bigram_mat/np.sum(bigram_mat, axis=1).reshape(-1, 1)  # reshape for broadcast\n",
    "bigram_cpts[np.isnan(bigram_cpts)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b456aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.806831Z",
     "start_time": "2021-10-24T03:35:54.803883Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK>: 0.61502\n",
      "U.: 0.013372\n",
      "FIRST: 0.01172\n",
      "COMPANY: 0.011659\n",
      "NEW: 0.009451\n",
      "UNITED: 0.008672\n",
      "GOVERNMENT: 0.006803\n",
      "NINETEEN: 0.006651\n",
      "SAME: 0.006287\n"
     ]
    }
   ],
   "source": [
    "the_idx = find_word_idx('THE')\n",
    "the_cpt = bigram_cpts[the_idx, :]\n",
    "top_10_idx = np.argsort(the_cpt)[:-10:-1]\n",
    "for idx in top_10_idx:\n",
    "    print(f'{vocabs[idx]}: {round(the_cpt[idx], 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb805c5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08428009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.810982Z",
     "start_time": "2021-10-24T03:35:54.807788Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_idx_map = dict()\n",
    "for word_idx, word in enumerate(vocabs):\n",
    "    word_idx_map[word] = word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb6ed2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.814559Z",
     "start_time": "2021-10-24T03:35:54.812182Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_ls = \"The stock market fell by one hundred points last week\".upper().split(' ')\n",
    "word_idx_ls = [word_idx_map[word] for word in word_ls]\n",
    "word_ls_new = ['<s>'] + word_ls\n",
    "word_idx_ls_new = [word_idx_map['<s>']] + word_idx_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d08534c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.819882Z",
     "start_time": "2021-10-24T03:35:54.815574Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for word THE, P_u_i=0.047151941408226795\n",
      "for word pair (<s>, THE), P_b_i=0.15865263383617936\n",
      "\n",
      "for word STOCK, P_u_i=3.1512507432007626e-05\n",
      "for word pair (THE, STOCK), P_b_i=0.0023297344616282465\n",
      "\n",
      "for word MARKET, P_u_i=2.4591455775476525e-08\n",
      "for word pair (STOCK, MARKET), P_b_i=0.10335803824686614\n",
      "\n",
      "for word FELL, P_u_i=6.506598614749057e-12\n",
      "for word pair (MARKET, FELL), P_b_i=0.0021157553246509003\n",
      "\n",
      "for word BY, P_u_i=2.7199381389047273e-14\n",
      "for word pair (FELL, BY), P_b_i=0.021586391790699825\n",
      "\n",
      "for word ONE, P_u_i=1.633507872142784e-16\n",
      "for word pair (BY, ONE), P_b_i=0.008177296664716208\n",
      "\n",
      "for word HUNDRED, P_u_i=6.568619493273902e-19\n",
      "for word pair (ONE, HUNDRED), P_b_i=0.2090605106566691\n",
      "\n",
      "for word POINTS, P_u_i=1.450857645838592e-22\n",
      "for word pair (HUNDRED, POINTS), P_b_i=0.0006082891563333546\n",
      "\n",
      "for word LAST, P_u_i=1.6837345533215323e-25\n",
      "for word pair (POINTS, LAST), P_b_i=0.005703211517165006\n",
      "\n",
      "for word WEEK, P_u_i=9.636204944731571e-29\n",
      "for word pair (LAST, WEEK), P_b_i=0.1639178408456196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P_b = 1\n",
    "P_u = 1\n",
    "\n",
    "for i in range(len(word_idx_ls_new)-1):\n",
    "    P_u_i = unigram_cpts[word_idx_ls_new[i+1]]\n",
    "    P_u *= P_u_i\n",
    "    print(f'for word {word_ls_new[i+1]}, P_u_i={P_u}')\n",
    "    P_b_i = bigram_cpts[word_idx_ls_new[i], word_idx_ls_new[i+1]]\n",
    "    P_b *= P_b_i\n",
    "    print(f'for word pair ({word_ls_new[i]}, {word_ls_new[i+1]}), P_b_i={P_b_i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6355ef15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.823705Z",
     "start_time": "2021-10-24T03:35:54.820959Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_u: -64.50944\n",
      "L_b: -40.918132\n",
      "L_b is higher than L_u\n"
     ]
    }
   ],
   "source": [
    "print(f'L_u: {round(np.log(P_u), 6)}')\n",
    "print(f'L_b: {round(np.log(P_b), 6)}')\n",
    "print('L_b is higher than L_u')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354bdf3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6755ed1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.827758Z",
     "start_time": "2021-10-24T03:35:54.825123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_ls = 'The sixteen officials sold fire insurance'.upper().split(' ')\n",
    "word_idx_ls = [word_idx_map[word] for word in word_ls]\n",
    "word_ls_new = ['<s>'] + word_ls\n",
    "word_idx_ls_new = [word_idx_map['<s>']] + word_idx_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f75bd99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.833590Z",
     "start_time": "2021-10-24T03:35:54.829668Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for word THE, P_u_i=0.047151941408226795\n",
      "for word pair (<s>, THE), P_b_i=0.15865263383617936\n",
      "\n",
      "for word SIXTEEN, P_u_i=9.538235390711064e-06\n",
      "for word pair (THE, SIXTEEN), P_b_i=0.0002285121421392212\n",
      "\n",
      "for word OFFICIALS, P_u_i=6.366061919286568e-09\n",
      "for word pair (SIXTEEN, OFFICIALS), P_b_i=0.0\n",
      "\n",
      "for word SOLD, P_u_i=1.290342318518533e-12\n",
      "for word pair (OFFICIALS, SOLD), P_b_i=9.162207725573554e-05\n",
      "\n",
      "for word FIRE, P_u_i=2.7918383925292573e-16\n",
      "for word pair (SOLD, FIRE), P_b_i=0.0\n",
      "\n",
      "for word INSURANCE, P_u_i=5.811085501680198e-20\n",
      "for word pair (FIRE, INSURANCE), P_b_i=0.003052399525182296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P_b = 1\n",
    "P_u = 1\n",
    "\n",
    "for i in range(len(word_idx_ls_new)-1):\n",
    "    P_u_i = unigram_cpts[word_idx_ls_new[i+1]]\n",
    "    P_u *= P_u_i\n",
    "    print(f'for word {word_ls_new[i+1]}, P_u_i={P_u}')\n",
    "    P_b_i = bigram_cpts[word_idx_ls_new[i], word_idx_ls_new[i+1]]\n",
    "    P_b *= P_b_i\n",
    "    print(f'for word pair ({word_ls_new[i]}, {word_ls_new[i+1]}), P_b_i={P_b_i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ee956d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.838911Z",
     "start_time": "2021-10-24T03:35:54.836729Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_u: -44.291934\n",
      "L_b: -inf\n"
     ]
    }
   ],
   "source": [
    "print(f'L_u: {round(np.log(P_u), 6)}')\n",
    "print(f'L_b: {round(np.log(P_b), 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d237",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Word pairs (SIXTEEN, OFFICIALS) and (SOLD, FIRE) in this sentence are not observed in the training corpus, therefore lead to zero P_b, and that makes log likelihood L_b to be infinity*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9376b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a58ece6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.843922Z",
     "start_time": "2021-10-24T03:35:54.840042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "P_m = 1\n",
    "word_ls_new = ['<s>'] + word_ls\n",
    "word_idx_ls_new = [word_idx_map['<s>']] + word_idx_ls\n",
    "P_b_ls = []\n",
    "P_u_ls = []\n",
    "for i in range(len(word_idx_ls_new)-1):\n",
    "    P_u_ls.append(unigram_cpts[word_idx_ls_new[i+1]])\n",
    "    P_b_ls.append(bigram_cpts[word_idx_ls_new[i], word_idx_ls_new[i+1]])\n",
    "\n",
    "P_u_arr = np.array(P_u_ls)\n",
    "P_b_arr = np.array(P_b_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38630413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.912442Z",
     "start_time": "2021-10-24T03:35:54.845698Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "split_num = 10000\n",
    "P_m_ls = []\n",
    "for i in range(0, split_num+1):\n",
    "    lambda_val = i/split_num\n",
    "    P_m = np.sum(np.log(lambda_val*P_u_arr + (1-lambda_val)*P_b_arr))\n",
    "    P_m_ls.append(P_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fdde89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T03:35:54.916395Z",
     "start_time": "2021-10-24T03:35:54.913489Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal lambda: 0.6479\n"
     ]
    }
   ],
   "source": [
    "print(f'optimal lambda: {np.argmax(P_m_ls)/split_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d7816",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
