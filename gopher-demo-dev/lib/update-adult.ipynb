{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:14.934503Z",
     "start_time": "2021-11-19T05:58:13.671102Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tqdm\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from load_dataset import load, generate_random_dataset\n",
    "from classifier import NeuralNetwork, LogisticRegression, SVM\n",
    "from utils import *\n",
    "from metrics import *  # include fairness and corresponding derivatives\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from operator import itemgetter\n",
    "from torch.autograd import grad\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T18:01:00.067474Z",
     "start_time": "2021-12-15T18:01:00.018209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f35d03e1fc44d1fa57e62f6f0d381cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='age', description='column'), IntSlider(value=10, description='x', max=30, mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "@interact\n",
    "def show_articles_more_than(column ='age', x = 10):\n",
    "    return X_train_orig.loc [df [column]> x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:14.938446Z",
     "start_time": "2021-11-19T05:58:14.935913Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T18:01:07.277766Z",
     "start_time": "2021-12-15T18:01:07.223855Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'german'\n",
    "X_train, X_test, y_train, y_test = load(dataset, sample=False)\n",
    "\n",
    "duplicates = 1\n",
    "make_duplicates = lambda x, d: pd.concat([x]*d, axis=0).reset_index(drop=True)\n",
    "X_train = make_duplicates(X_train, duplicates)\n",
    "X_test = make_duplicates(X_test, duplicates)\n",
    "y_train = make_duplicates(y_train, duplicates)\n",
    "y_test = make_duplicates(y_test, duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.112093Z",
     "start_time": "2021-11-19T05:58:15.105053Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# Scale data: regularization penalty default: ‘l2’, ‘lbfgs’ solvers support only l2 penalties. \n",
    "# Regularization makes the predictor dependent on the scale of the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function** (Log loss for logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.117800Z",
     "start_time": "2021-11-19T05:58:15.113953Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = NeuralNetwork(input_size=X_train.shape[-1])\n",
    "clf = LogisticRegression(input_size=X_train.shape[-1])\n",
    "# clf = SVM(input_size=X_train.shape[-1])\n",
    "num_params = len(convert_grad_to_ndarray(list(clf.parameters())))\n",
    "if isinstance(clf, LogisticRegression) or isinstance(clf, NeuralNetwork):\n",
    "    loss_func = lambda model, x, y_true: logistic_loss_torch(model, x, y_true, 0)\n",
    "elif isinstance(clf, SVM):\n",
    "    loss_func = svm_loss_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.120470Z",
     "start_time": "2021-11-19T05:58:15.118665Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computeAccuracy(y_true, y_pred):\n",
    "    return np.sum((y_pred>0.5) == y_true)/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of loss function at z with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.123877Z",
     "start_time": "2021-11-19T05:58:15.121320Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_L_del_theta_i(model, x, y_true, retain_graph=False):\n",
    "    loss = loss_func(model, x, y_true)\n",
    "    w = [ p for p in model.parameters() if p.requires_grad ]\n",
    "    return grad(loss, w, create_graph=True, retain_graph=retain_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of $P(y \\mid \\textbf{x})$ with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.127298Z",
     "start_time": "2021-11-19T05:58:15.124903Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_f_del_theta_i(model, x, retain_graph=False):\n",
    "    w = [ p for p in model.parameters() if p.requires_grad ]\n",
    "    return grad(model(torch.FloatTensor(x)), w, retain_graph=retain_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic estimation of Hessian vector product (involving del fairness): $H_{\\theta}^{-1}v = H_{\\theta}^{-1}\\nabla_{\\theta}f(z, \\theta) = v + [I - \\nabla_{\\theta}^2L(z_{s_j}, \\theta^*)]H_{\\theta}^{-1}v$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.130958Z",
     "start_time": "2021-11-19T05:58:15.128172Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def hvp(y, w, v):\n",
    "    ''' Multiply the Hessians of y and w by v.'''\n",
    "    # First backprop\n",
    "    first_grads = grad(y, w, retain_graph=True, create_graph=True)\n",
    "\n",
    "    # Elementwise products\n",
    "    elemwise_products = 0\n",
    "    for grad_elem, v_elem in zip(convert_grad_to_tensor(first_grads), v):\n",
    "        elemwise_products += torch.sum(grad_elem * v_elem)\n",
    "\n",
    "    # Second backprop\n",
    "    return_grads = grad(elemwise_products, w, create_graph=True)\n",
    "\n",
    "    return return_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.135004Z",
     "start_time": "2021-11-19T05:58:15.131909Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def hessian_one_point(model, x, y):\n",
    "    x, y = torch.FloatTensor(x), torch.FloatTensor([y])\n",
    "    loss = loss_func(model, x, y)\n",
    "    params = [ p for p in model.parameters() if p.requires_grad ]\n",
    "    first_grads = convert_grad_to_tensor(grad(loss, params, retain_graph=True, create_graph=True))\n",
    "    hv = np.zeros((len(first_grads), len(first_grads)))\n",
    "    for i in range(len(first_grads)):\n",
    "        hv[i, :] = convert_grad_to_ndarray(grad(first_grads[i], params, create_graph=True)).ravel()\n",
    "    return hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.141826Z",
     "start_time": "2021-11-19T05:58:15.135938Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Compute multiplication of inverse hessian matrix and vector v\n",
    "def s_test(model, xs, ys, v, hinv=None, damp=0.01, scale=25.0, r=-1, batch_size=-1, recursive=False, verbose=False):\n",
    "    ''' Arguments:\n",
    "        xs: list of data points\n",
    "        ys: list of true labels corresponding to data points in xs\n",
    "        damp: dampening factor\n",
    "        scale: scaling factor\n",
    "        r: number of iterations aka recursion depth\n",
    "            should be enough so that the value stabilises.\n",
    "        batch_size: number of instances in each batch in recursive approximation\n",
    "        recursive: determine whether to recursively approximate hinv_v'''\n",
    "    xs, ys = torch.FloatTensor(xs.copy()), torch.FloatTensor(ys.copy())\n",
    "    n = len(xs)\n",
    "    if recursive:\n",
    "        hinv_v = copy.deepcopy(v)\n",
    "        if verbose:\n",
    "            print('Computing s_test...')\n",
    "            tbar = tqdm.tqdm(total=r)\n",
    "        if (batch_size == -1):  # default\n",
    "            batch_size = 10\n",
    "        if (r == -1):\n",
    "            r = n // batch_size + 1\n",
    "        sample = np.random.choice(range(n), r*batch_size, replace=True)\n",
    "        for i in range(r):\n",
    "            sample_idx = sample[i*batch_size:(i+1)*batch_size]\n",
    "            x, y = xs[sample_idx], ys[sample_idx]\n",
    "            loss = loss_func(model, x, y)\n",
    "            params = [ p for p in model.parameters() if p.requires_grad ]\n",
    "            hv = convert_grad_to_ndarray(hvp(loss, params, torch.FloatTensor(hinv_v)))\n",
    "            # Recursively caclulate h_estimate\n",
    "            hinv_v = v + (1 - damp) * hinv_v - hv / scale\n",
    "            if verbose:\n",
    "                tbar.update(1)\n",
    "    else:\n",
    "        if hinv is None:\n",
    "            hinv = np.linalg.pinv(np.sum(hessian_all_points, axis=0))\n",
    "        scale = 1.0\n",
    "        hinv_v = np.matmul(hinv, v)\n",
    "\n",
    "    return hinv_v / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics: Initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.706367Z",
     "start_time": "2021-11-19T05:58:15.142867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial statistical parity:  -0.1937291073930064\n",
      "Initial TPR parity:  -0.180429660523945\n",
      "Initial predictive parity:  -0.18632730832832872\n",
      "Initial loss:  0.3978844808353249\n",
      "Initial accuracy:  0.801394422310757\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(input_size=X_train.shape[-1])\n",
    "# clf = NeuralNetwork(input_size=X_train.shape[-1])\n",
    "# clf = SVM(input_size=X_train.shape[-1])\n",
    "\n",
    "clf.fit(X_train, y_train, use_sklearn=True)\n",
    "\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "\n",
    "spd_0 = computeFairness(y_pred_test, X_test_orig, y_test, 0, dataset)\n",
    "print(\"Initial statistical parity: \", spd_0)\n",
    "\n",
    "tpr_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 1, dataset)\n",
    "print(\"Initial TPR parity: \", tpr_parity_0)\n",
    "\n",
    "predictive_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 2, dataset)\n",
    "print(\"Initial predictive parity: \", predictive_parity_0)\n",
    "\n",
    "loss_0 = logistic_loss(y_test, y_pred_test)\n",
    "print(\"Initial loss: \", loss_0)\n",
    "\n",
    "accuracy_0 = computeAccuracy(y_test, y_pred_test)\n",
    "print(\"Initial accuracy: \", accuracy_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.709628Z",
     "start_time": "2021-11-19T05:58:15.707687Z"
    }
   },
   "outputs": [],
   "source": [
    "# hessian_all_points = []\n",
    "# tbar = tqdm.tqdm(total=len(X_train))\n",
    "# total_time = 0\n",
    "# for i in range(len(X_train)):\n",
    "#     t0 = time.time()\n",
    "#     hessian_all_points.append(hessian_one_point(clf, X_train[i], y_train[i])/len(X_train))\n",
    "#     total_time += time.time()-t0\n",
    "#     tbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:15.714654Z",
     "start_time": "2021-11-19T05:58:15.713017Z"
    }
   },
   "outputs": [],
   "source": [
    "# hessian_all_points = np.array(hessian_all_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-compute: del_L_del_theta for each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:22.616559Z",
     "start_time": "2021-11-19T05:58:15.715602Z"
    }
   },
   "outputs": [],
   "source": [
    "del_L_del_theta = []\n",
    "for i in range(int(len(X_train))):\n",
    "    gradient = convert_grad_to_ndarray(del_L_del_theta_i(clf, X_train[i], int(y_train[i])))\n",
    "    while np.sum(np.isnan(gradient))>0:\n",
    "        gradient = convert_grad_to_ndarray(del_L_del_theta_i(clf, X_train[i], int(y_train[i])))\n",
    "    del_L_del_theta.append(gradient)\n",
    "del_L_del_theta = np.array(del_L_del_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Select delta fairness function depending on selected metric*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:25.037204Z",
     "start_time": "2021-11-19T05:58:22.617416Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = 0\n",
    "if metric == 0:\n",
    "    v1 = del_spd_del_theta(clf, X_test_orig, X_test, dataset)\n",
    "elif metric == 1:\n",
    "    v1 = del_tpr_parity_del_theta(clf, X_test_orig, X_test, y_test, dataset)\n",
    "elif metric == 2:\n",
    "    v1 = del_predictive_parity_del_theta(clf, X_test_orig, X_test, y_test, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:25.041847Z",
     "start_time": "2021-11-19T05:58:25.038236Z"
    }
   },
   "outputs": [],
   "source": [
    "# def del_L_del_delta_i(num_params, x, y_pred, params, y_true):\n",
    "#     del_L_del_delta = np.ones((num_params - 1, num_params)) * (y_pred[0] * y_pred[1])\n",
    "#     for i in range(num_params - 1):\n",
    "#         for j in range(num_params):\n",
    "#             del_L_del_delta[i][j] *=  params[i]\n",
    "#             if j != 0:\n",
    "#                 del_L_del_delta[i][j] *=  x[j - 1]\n",
    "#                 if j == i:\n",
    "#                     del_L_del_delta[i][j] += y_pred[1] - y_true\n",
    "            \n",
    "#     return del_L_del_delta\n",
    "\n",
    "# def del_L_del_delta_i(model, x, delta, y_true, retain_graph=False):\n",
    "#     loss = loss_func(model, x+delta, y_true)\n",
    "#     return grad(loss, delta, create_graph=True, retain_graph=retain_graph)\n",
    "def del_L_del_theta_del_delta_i(model, x, delta, y_true):\n",
    "    x, delta, y = torch.FloatTensor(x), torch.FloatTensor(delta), torch.FloatTensor([y_true])\n",
    "    delta.requires_grad = True\n",
    "    loss = loss_func(model, x+delta, y)\n",
    "    params = [ p for p in model.parameters() if p.requires_grad ]\n",
    "    first_grads = convert_grad_to_tensor(grad(loss, params, retain_graph=True, create_graph=True))\n",
    "    result = np.zeros((x.shape[1], len(first_grads)))\n",
    "    for i in range(len(first_grads)):\n",
    "        result[:, i] = convert_grad_to_ndarray(grad(first_grads[i], delta, create_graph=True)).ravel()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:25.049241Z",
     "start_time": "2021-11-19T05:58:25.042723Z"
    }
   },
   "outputs": [],
   "source": [
    "def repair(idx, numIter, learningRate):\n",
    "    clf.fit(X_train, y_train, use_sklearn=True)\n",
    "    y_pred_test = clf.predict_proba(X_test)\n",
    "    \n",
    "    X_p = copy.deepcopy(X_train[idx])\n",
    "    y_p_true = copy.deepcopy(y_train[idx]) \n",
    "\n",
    "    del_L_del_delta = np.zeros((X_train.shape[1], num_params))\n",
    "    \n",
    "#     torch.manual_seed(1)\n",
    "#     delta_new = torch.rand((X_train.shape[1], 1))\n",
    "    random.seed(0)\n",
    "    delta_new = np.zeros((num_params - 1, 1))\n",
    "    for i in range(len(delta_new)):\n",
    "        delta_new[i] = random.random()\n",
    "    delta_new = torch.FloatTensor(delta_new)\n",
    "    threshold = 0.05\n",
    "    delta_old = -1 * torch.ones((X_train.shape[1], 1))\n",
    "\n",
    "    num_iter = 0\n",
    "    del_L_del_theta_Xp = np.sum(del_L_del_theta[idx, :], axis=0).reshape(-1, 1)\n",
    "    obj_old = np.dot(del_L_del_theta_Xp.transpose(), v1)\n",
    "    obj_new = obj_old + 0.1\n",
    "    print(obj_old, obj_new)\n",
    "\n",
    "    while (obj_new > obj_old):\n",
    "        obj_old = obj_new\n",
    "        num_iter += 1\n",
    "        del_L_del_delta = del_L_del_theta_del_delta_i(clf, X_train[idx, :], delta_new.ravel(), np.array(y_train[idx]))\n",
    "        delta_old = delta_new\n",
    "        delta_new += (learningRate/num_iter) * np.dot(del_L_del_delta, v1).reshape(-1, 1)\n",
    "        \n",
    "        print(delta_new, (learningRate/num_iter) * np.dot(del_L_del_delta, v1).reshape(-1, 1))\n",
    "        X_train_perturbed = copy.deepcopy(X_train)\n",
    "        X_train_perturbed[idx, :] += delta_new.detach().numpy().squeeze()\n",
    "            \n",
    "        del_L_del_theta_Xp = convert_grad_to_ndarray(del_L_del_theta_i(clf, X_train_perturbed[idx, :], np.array(y_train[idx]))).reshape(-1, 1)\n",
    "        obj_new = np.dot(del_L_del_theta_Xp.transpose(), v1)\n",
    "        print(obj_old, obj_new)\n",
    "        if ((obj_new < obj_old)):\n",
    "            return delta_old\n",
    "    \n",
    "    return delta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T06:18:07.716473Z",
     "start_time": "2021-11-19T06:18:07.652978Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "clf.fit(X_train, y_train, use_sklearn=True)\n",
    "delta_new = np.zeros((num_params - 1, 1))\n",
    "for i in range(len(delta_new)):\n",
    "    delta_new[i] = random.random()\n",
    "delta_new = torch.FloatTensor(delta_new)\n",
    "\n",
    "x, delta, y = X_train[idx[0], :], delta_new.ravel(), np.array(y_train)[idx[0]]\n",
    "x, y = torch.FloatTensor([x])+torch.FloatTensor(delta), torch.FloatTensor([y])\n",
    "x.requires_grad = True\n",
    "loss = loss_func(clf, x, y)\n",
    "params = [ p for p in clf.parameters() if p.requires_grad ]\n",
    "first_grads = convert_grad_to_tensor(grad(loss, params, retain_graph=True, create_graph=True))\n",
    "result = np.zeros((x.shape[1], len(first_grads)))\n",
    "for i in range(len(first_grads)):\n",
    "    result[:, i] = convert_grad_to_ndarray(grad(first_grads[i], x, create_graph=True)).ravel()/len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T06:19:31.689661Z",
     "start_time": "2021-11-19T06:19:31.682325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88456625,  0.48002872,  0.62960243,  0.03082163, -0.15646912,\n",
       "        0.30763996, -0.25090474, -0.13656567,  0.38038546], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_grads.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T06:03:41.270914Z",
     "start_time": "2021-11-19T06:03:41.263232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8846,  0.4800,  0.6296,  0.0308, -0.1565,  0.3076, -0.2509, -0.1366,\n",
       "         0.3804], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T06:05:25.425934Z",
     "start_time": "2021-11-19T06:05:25.416990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04982051, -0.01277423,  0.14352342,  0.11147176,  0.1353553 ,\n",
       "        0.01770828,  0.03118311,  0.07162918], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_grad_to_ndarray(grad(first_grads[-1], x, create_graph=True)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T05:58:34.606817Z",
     "start_time": "2021-11-19T05:58:34.538511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.71182258] [9.81182258]\n",
      "tensor([[0.8458],\n",
      "        [0.7554],\n",
      "        [0.4400],\n",
      "        [0.2452],\n",
      "        [0.4933],\n",
      "        [0.4008],\n",
      "        [0.7296],\n",
      "        [0.2977]], dtype=torch.float64) [[ 0.00139519]\n",
      " [-0.00258672]\n",
      " [ 0.0194724 ]\n",
      " [-0.01372312]\n",
      " [-0.01795746]\n",
      " [-0.00417402]\n",
      " [-0.05422114]\n",
      " [-0.00560575]]\n",
      "[9.81182258] [0.03442867]\n"
     ]
    }
   ],
   "source": [
    "idx = X_train_orig[\n",
    "    (X_train_orig['gender'] == 0)\n",
    "    & (X_train_orig['relationship'] == 0)\n",
    "    & (X_train_orig['education'] == 12)\n",
    "    & (X_train_orig['race'] == 1)\n",
    "    ].index\n",
    "# v_pert = repair(idx, numIter, learningRate)\n",
    "v_pert = repair(idx, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T01:52:06.172159Z",
     "start_time": "2021-11-18T01:52:06.146772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29779</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30004</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30131</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30144</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30147</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  education  marital  relationship  race  gender  hours  \\\n",
       "90       1          7         12        1             0     1       0      0   \n",
       "120      0          7         12        0             0     1       0      1   \n",
       "201      1          7         12        1             0     1       0      0   \n",
       "285      1          7         12        0             0     1       0      0   \n",
       "340      0          7         12        0             0     1       0      0   \n",
       "...    ...        ...        ...      ...           ...   ...     ...    ...   \n",
       "29779    1          6         12        0             0     1       0      0   \n",
       "30004    0          7         12        1             0     1       0      0   \n",
       "30131    0          7         12        0             0     1       0      0   \n",
       "30144    1          3         12        1             0     1       0      1   \n",
       "30147    0          7         12        1             0     1       0      0   \n",
       "\n",
       "       income  \n",
       "90          0  \n",
       "120         0  \n",
       "201         0  \n",
       "285         0  \n",
       "340         0  \n",
       "...       ...  \n",
       "29779       0  \n",
       "30004       0  \n",
       "30131       0  \n",
       "30144       0  \n",
       "30147       0  \n",
       "\n",
       "[262 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = copy.deepcopy(X_train_orig)\n",
    "df['income'] = y_train\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T01:52:06.733691Z",
     "start_time": "2021-11-18T01:52:06.712052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15055</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15056</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15057</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15058</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15059</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  education  marital  relationship  race  gender  hours\n",
       "0        0          7          6        0             0     0       1      0\n",
       "1        0          7          8        2             1     1       1      1\n",
       "2        0          3         12        2             1     1       1      0\n",
       "3        0          7          9        2             1     0       1      0\n",
       "4        0          7          5        0             0     1       1      0\n",
       "...    ...        ...        ...      ...           ...   ...     ...    ...\n",
       "15055    0          7         10        0             0     1       1      0\n",
       "15056    0          7         10        1             0     1       0      0\n",
       "15057    0          7         10        2             1     1       1      1\n",
       "15058    0          7         10        1             0     0       1      0\n",
       "15059    0          5         10        2             1     1       1      1\n",
       "\n",
       "[15060 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T01:52:07.247594Z",
     "start_time": "2021-11-18T01:52:07.237283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01934698, 0.41743198, 0.5349799 , ..., 0.53971857, 0.08282077,\n",
       "       0.5580527 ], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T01:53:52.562266Z",
     "start_time": "2021-11-18T01:53:20.193715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5857465864596665 6.9999987139550495 10.402278396946304 1.674998151183459 0.7527654848444509 0.9999999276573958 0.9508437383210989 0.5755269090306605\n",
      "-0.019808927249723607\n",
      "CPU times: user 59.9 s, sys: 4.16 s, total: 1min 4s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_age = []\n",
    "res_workclass = []\n",
    "res_education = []\n",
    "res_marital = []\n",
    "res_relationship = []\n",
    "res_race = []\n",
    "res_gender = []\n",
    "res_hours = []\n",
    "\n",
    "X_train_copy = copy.deepcopy(X_train)\n",
    "numCols = len(X_train_orig.columns)\n",
    "for ix in range(len(idx)):\n",
    "    X_train_pert = np.zeros((len(X_train[idx[ix]]), 1))\n",
    "    for i in range(len(X_train[idx[ix]])):\n",
    "        X_train_pert[i] = X_train[idx[ix]][i] + v_pert[i]\n",
    "\n",
    "    x0 = np.random.rand(1,numCols)\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    numCols = len(X_train[0])\n",
    "    for i in range(numCols):\n",
    "        mins.insert(i, min(X_train[:,i]))\n",
    "        maxs.insert(i, max(X_train[:,i]))\n",
    "\n",
    "    from scipy.optimize import Bounds, minimize\n",
    "    bounds = Bounds(mins, maxs)\n",
    "\n",
    "    f = lambda x: np.linalg.norm(x - X_train_pert)\n",
    "\n",
    "    x0 = np.random.rand(numCols)\n",
    "    res = minimize(f, x0, method='trust-constr', options={'verbose': 0}, bounds=bounds)\n",
    "    \n",
    "    for i in range(len(X_train_copy[idx[ix]])):\n",
    "        X_train_copy[idx[ix]][i] = res.x[i]\n",
    "        \n",
    "#     res_x_inv_transform = sc.inverse_transform(res.x, copy=None)\n",
    "    res_x_inv_transform = sc.inverse_transform(X_train_copy[idx[ix]], copy=None)\n",
    "#     res_x_inv_transform = sc.inverse_transform(X_train_copy[idx[ix]], copy=None)\n",
    "    res_age.insert(ix, res_x_inv_transform[0])\n",
    "    res_workclass.insert(ix, res_x_inv_transform[1])\n",
    "    res_education.insert(ix, res_x_inv_transform[2])\n",
    "    res_marital.insert(ix, res_x_inv_transform[3])\n",
    "    res_relationship.insert(ix, res_x_inv_transform[4])\n",
    "    res_race.insert(ix, res_x_inv_transform[5])\n",
    "    res_gender.insert(ix, res_x_inv_transform[6])\n",
    "    res_hours.insert(ix, res_x_inv_transform[7])\n",
    "\n",
    "clf.fit(X_train_copy, y_train, use_sklearn=True)\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "\n",
    "import statistics\n",
    "print(statistics.mode(res_age), statistics.mode(res_workclass), statistics.mode(res_education), \n",
    "      statistics.mode(res_marital), statistics.mode(res_relationship), \n",
    "      statistics.mode(res_race), statistics.mode(res_gender), statistics.mode(res_hours))\n",
    "print(computeFairness(y_pred_test, X_test_orig, y_test, 0, dataset)\n",
    "      /spd_0 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initial: [[ 0.32698744  2.20756884  0.52520941  0.26284814 -0.14408554]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('salary.data', names=cols, sep=\"\\t\", index_col=False)\n",
    "df = preprocess(df)\n",
    "# df[df['status', 'credit'].groupby(by=\"credit\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T01:59:53.085771Z",
     "start_time": "2021-11-18T01:59:52.925408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18989370294446486"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_copy, y_train, use_sklearn=True)\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "computeFairness(y_pred_test, X_test_orig, y_test, 0, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeFairness(y_pred_test, X_test_orig, y_test, 0, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
