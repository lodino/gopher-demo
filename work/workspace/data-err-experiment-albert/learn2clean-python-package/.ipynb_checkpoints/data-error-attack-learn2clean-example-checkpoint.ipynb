{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ef6ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:11.630117Z",
     "start_time": "2024-03-16T19:20:08.755405Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load_dataset'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "import optuna\n",
    "import pickle\n",
    "\n",
    "import learn2clean\n",
    "import learn2clean.loading.reader as rd \n",
    "import learn2clean.qlearning.qlearner as ql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from load_dataset import load\n",
    "from classifier import *\n",
    "from utils import *\n",
    "from metrics import *  # include fairness and corresponding derivatives\n",
    "from API_Design_a import MissingValueError, SamplingError, Injector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.metrics import mutual_info_score, auc, roc_curve, roc_auc_score, f1_score\n",
    "from scipy.stats import wasserstein_distance\n",
    "from optuna.samplers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75063ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:11.634072Z",
     "start_time": "2024-03-16T19:20:11.631694Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7c22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:11.637827Z",
     "start_time": "2024-03-16T19:20:11.635870Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'adult'\n",
    "sens_attr = 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c2116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:12.155001Z",
     "start_time": "2024-03-16T19:20:11.639481Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135e986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:12.163866Z",
     "start_time": "2024-03-16T19:20:12.156252Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# Use 1/4 of training data as validation set\n",
    "X_train_orig, X_val_orig, y_train, y_val = \\\n",
    "    train_test_split(X_train_orig, y_train, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e056517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:12.168756Z",
     "start_time": "2024-03-16T19:20:12.165298Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_orig, X_val_orig, X_test_orig = (X_train_orig.reset_index(drop=True), \n",
    "                                         X_val_orig.reset_index(drop=True),\n",
    "                                         X_test_orig.reset_index(drop=True))\n",
    "y_train, y_test = y_train.reset_index(drop=True), y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebe7c6",
   "metadata": {},
   "source": [
    "## Learn2Clean with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26058abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:12.174503Z",
     "start_time": "2024-03-16T19:20:12.170185Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8cafa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:12.185131Z",
     "start_time": "2024-03-16T19:20:12.177055Z"
    }
   },
   "outputs": [],
   "source": [
    "# create pattern function given subpopulation\n",
    "def create_pattern(col_list, lb_list, ub_list):\n",
    "    try:\n",
    "        assert len(col_list) == len(lb_list) == len(ub_list)\n",
    "    except:\n",
    "        print(col_list, lb_list, ub_list)\n",
    "        raise SyntaxError\n",
    "    def pattern(data_X, data_y):\n",
    "        binary_indicators = []\n",
    "        for i in data_X.index:\n",
    "            satisfaction = True\n",
    "            for j in range(len(col_list)):\n",
    "                if col_list[j] == 'Y':\n",
    "                    if (data_y.loc[i] < lb_list[j]) or (data_y.loc[i] > ub_list[j]):\n",
    "                        satisfaction = False\n",
    "                        break\n",
    "                else:\n",
    "                    if (data_X.loc[i, col_list[j]] < lb_list[j]) or (data_X.loc[i, col_list[j]] > ub_list[j]):\n",
    "                        satisfaction = False\n",
    "                        break\n",
    "            if satisfaction:\n",
    "                binary_indicators.append(1)\n",
    "            else:\n",
    "                binary_indicators.append(0)\n",
    "        return np.array(binary_indicators)\n",
    "    return pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d4428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:12.189666Z",
     "start_time": "2024-03-16T19:20:12.187249Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not(os.path.exists('./save/')):\n",
    "    os.system('mkdir ./save/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4392070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:20:18.739768Z",
     "start_time": "2024-03-16T19:20:12.190939Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean data\n",
    "learn2clean_dataset = {\"train\": X_train_orig, \"test\": X_test_orig, \n",
    "                       \"target\": y_train, \"target_test\": y_test}\n",
    "\n",
    "# file name only used for the name of saved log, cannot be None.\n",
    "# target goal is the name of y (y_train and y_test should be pandas Series)\n",
    "l2c_c1assification1 = ql.Qlearner(dataset=learn2clean_dataset, goal='CART', target_goal='income',\n",
    "                                  threshold=0.6, target_prepare=None, \n",
    "                                  file_name='adult', verbose=False)\n",
    "baseline_auc = l2c_c1assification1.learn2clean()\n",
    "baseline_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1603c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T09:18:35.066501Z",
     "start_time": "2024-03-16T09:18:35.064389Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3c307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:39:19.762603Z",
     "start_time": "2024-03-16T19:20:18.741618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "budget = 4000\n",
    "col_list = ['education', 'marital', 'gender', 'Y']\n",
    "def objective(trial, budget=budget/2, col_id=3, precedent_injection=[]):\n",
    "    lb_list = []\n",
    "    ub_list = []\n",
    "    for col in col_list:\n",
    "        if col == 'Y':\n",
    "            mv_lb = trial.suggest_int(col+'_mv_lb', y_train.min(), y_train.max())\n",
    "            lb_list.append(mv_lb)\n",
    "            mv_interval = trial.suggest_int(col+'_mv_int', 0, y_train.max() - mv_lb)\n",
    "            mv_ub = mv_interval + mv_lb\n",
    "            ub_list.append(mv_ub) \n",
    "        else:\n",
    "            mv_lb = trial.suggest_int(col+'_mv_lb', X_train_orig[col].min(), X_train_orig[col].max())\n",
    "            lb_list.append(mv_lb)\n",
    "            mv_interval = trial.suggest_int(col+'_mv_int', 0, X_train_orig[col].max() - mv_lb)\n",
    "            mv_ub = mv_interval + mv_lb\n",
    "            ub_list.append(mv_ub)\n",
    "\n",
    "    mv_pattern = create_pattern(col_list, lb_list, ub_list)\n",
    "    mv_pattern_len = np.sum(mv_pattern(X_train_orig, y_train))\n",
    "    if mv_pattern_len == 0:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    mv_num = min(mv_pattern_len, budget)\n",
    "    \n",
    "    mv_err = MissingValueError(col_id, mv_pattern, mv_num/mv_pattern_len)\n",
    "    injecter = Injector(error_seq = precedent_injection + [mv_err])\n",
    "    dirty_X_train_orig, dirty_y_train, _, _ = injecter.inject(X_train_orig.copy(), y_train.copy(),\n",
    "                                                              X_train_orig, y_train)\n",
    "    \n",
    "    # learn2clean\n",
    "    learn2clean_dataset = {\"train\": dirty_X_train_orig, \"test\": X_test_orig, \n",
    "                           \"target\": dirty_y_train, \"target_test\": y_test}\n",
    "\n",
    "    l2c_c1assification1 = ql.Qlearner(dataset=learn2clean_dataset, goal='CART', target_goal='income',\n",
    "                                      target_prepare=None, file_name='adult', verbose=False)\n",
    "    auc = l2c_c1assification1.learn2clean()\n",
    "    \n",
    "    auc_drop = auc - baseline_auc\n",
    "    trial.set_user_attr('num_errs', mv_num)\n",
    "    trial.set_user_attr('auc_drop', auc_drop)\n",
    "    trial.set_user_attr('error_injector', injecter)\n",
    "    return auc_drop\n",
    "\n",
    "\n",
    "# optimize for first injection (3rd column: education)\n",
    "study1 = optuna.create_study(sampler=TPESampler(seed=budget))\n",
    "study1.optimize(lambda trial: objective(trial, budget=budget, col_id=3, \n",
    "                                        precedent_injection=[]), n_trials=50)\n",
    "\n",
    "learned_err_injection_list = study1.best_trial.user_attrs['error_injector'].error_seq\n",
    "num_errs_used = study1.best_trial.user_attrs['num_errs']\n",
    "print(f\"Injected {num_errs_used} errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5994bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T09:40:38.071126Z",
     "start_time": "2024-03-01T09:40:38.066152Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96dbc96f",
   "metadata": {},
   "source": [
    "Now we use the learned injector to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e0c80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:39:46.849594Z",
     "start_time": "2024-03-16T19:39:19.764700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learned_injector = study1.best_trial.user_attrs['error_injector']\n",
    "dirty_X_train_orig, dirty_y_train, _, _ = learned_injector.inject(X_train_orig.copy(), y_train.copy(),\n",
    "                                                                  X_train_orig, y_train)\n",
    "\n",
    "learn2clean_dataset = {\"train\": dirty_X_train_orig, \"test\": X_test_orig, \n",
    "                       \"target\": dirty_y_train, \"target_test\": y_test}\n",
    "\n",
    "l2c_c1assification1 = ql.Qlearner(dataset=learn2clean_dataset, goal='CART', target_goal='income',\n",
    "                                  target_prepare=None, file_name='adult', verbose=False)\n",
    "auc = l2c_c1assification1.learn2clean()\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c68db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bce1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T19:39:53.772352Z",
     "start_time": "2024-03-16T19:39:53.763412Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_auc - auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b35aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
